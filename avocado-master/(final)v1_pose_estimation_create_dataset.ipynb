{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcef892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817e2e2",
   "metadata": {},
   "source": [
    "# head (머리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0962b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['head']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4246399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head (972, 141)\n",
      "head (942, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/head/head_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eca487",
   "metadata": {},
   "source": [
    "# shoulder (어깨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ea7bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['shoulder']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c8a6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoulder (1054, 141)\n",
      "shoulder (1024, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/shoulder/shoulder_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 1)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b255fd",
   "metadata": {},
   "source": [
    "# knee (무릎)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf10f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['knee']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cf146fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knee (952, 141)\n",
      "knee (922, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/knee/knee_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 2)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79e564",
   "metadata": {},
   "source": [
    "# clap (박수 짝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "848ec9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['clap']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5589a297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clap (1081, 141)\n",
      "clap (1051, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/clap/clap_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 3)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de656463",
   "metadata": {},
   "source": [
    "# left_foot (왼발 쿵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "697ffb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['left_foot']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43d6934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_foot (1021, 141)\n",
      "left_foot (991, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/left_foot/left_foot_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 4)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa12e4",
   "metadata": {},
   "source": [
    "# right_foot (오른발 쿵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13f27f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['right_foot']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1318921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_foot (914, 141)\n",
      "right_foot (884, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/right_foot/right_foot_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 5)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e4afc",
   "metadata": {},
   "source": [
    "# both_foot (양발 쿵)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48b10e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['both_foot']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5299e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both_foot (750, 141)\n",
      "both_foot (720, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/both_foot/both_foot_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 6)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f099b36",
   "metadata": {},
   "source": [
    "#  yeah (예!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0056c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['yeah']\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    enable_segmentation=False,\n",
    "                    smooth_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8764a272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah (921, 141)\n",
      "yeah (891, 30, 141)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./data_video/yeah/yeah_yj.mp4')\n",
    "# cap = cv2.VideoCapture(\"http://192.168.0.9:4747/video\")\n",
    "\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    data = []\n",
    "    while cap.isOpened():\n",
    "    \n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        img = cv2.resize(img, (0,0), fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.pose_landmarks is not None:\n",
    "            joint = np.zeros((33, 4))\n",
    "            for j, res in enumerate(result.pose_landmarks.landmark):\n",
    "                joint[j] = [res.x, res.y, res.z, res.visibility]\n",
    "\n",
    "            # Compute angles between joints\n",
    "            v1 = joint[[13, 14, 15, 16, 17, 18, 25, 26, 27, 28, 29, 30], :3] # Parent joint\n",
    "            v2 = joint[[11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28], :3] # Child joint\n",
    "            v = v2 - v1 # [12, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            v = np.nan_to_num(v)\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0, 1, 2, 3, 6, 7, 8, 9],:], \n",
    "                v[[2, 3, 4, 5, 8, 9, 10, 11],:])) # [8,]\n",
    "\n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx + 7)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    data = np.array(data)\n",
    "    print(action, data.shape)\n",
    "    np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "    # Create sequence data\n",
    "    full_seq_data = []\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    print(action, full_seq_data.shape)\n",
    "    np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
